{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensors and Torch Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor creation operations\n",
    "Specify shape and dtype as arguments. Shape can be a single integer, or tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A vector of 10 ones\n",
    "torch.ones(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A (3, 3) matrix of 0s as integers\n",
    "torch.zeros((3, 3), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A (2, 4, 4) tensor of numbers from standard normal distribution\n",
    "torch.randn((2, 4, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor shapes\n",
    "- Row vector: (B, 1)\n",
    "- Feature matrix: (B, D)\n",
    "- Greyscale images: (B, W, H, 1)\n",
    "- RGB images: (B, W, H, 3)\n",
    "- Arbitrary images: (B, W, H, C)\n",
    "- Sequences of vectors: (B, L, D)\n",
    "\n",
    "Create tensors of random numbers that have the same shapes as specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a feature matrix with 4 examples whose feature size is 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a batch of 5 RGB images whose spatial dimensions are 32x32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a batch of 2 vector sequences, whose sequence lengths are 7 and feature dimension is 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch dtypes\n",
    "Some useful conversions:\n",
    "- `torch.FloatTensor()` can be used to create tensors of `torch.float32` dtype\n",
    "- `torch.LongTensor()` can be used to create tensors of `torch.int64` dtype\n",
    "- Numpy arrays can be converted with `torch.from_numpy(x)`\n",
    "- `dtype` can be specified in some creation operations\n",
    "- Tensors can be cast using `x.type(new_type)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor indexing\n",
    "\n",
    "A tensor dimension of size D can be indexed in the following ways:\n",
    "- Single integers from [0, D-1] or [-D, -1] for reverse indices\n",
    "- Lists of integers or tensors of integer dtypes\n",
    "- Slices, using colon notation, or slice objects\n",
    "- Boolean masks of size D (or broadcastable)\n",
    "- Ellipsis to infer other dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(12)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single integer indexing\n",
    "a[1], a[-1], a[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List indexing\n",
    "a[[1, 3, 5]], a[[2, 2, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single colon represents entire dim, here we select all of row 0\n",
    "b = a.reshape(3, 4)\n",
    "b, b[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colons can represent ranges by `start:end`, exclusive of end when specified. Infers beginning or end\n",
    "a[0:3], a[:5], a[5:], a[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean masks can be used to select based on conditions\n",
    "mask = a < 5\n",
    "a[mask], mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ellipsis can infer dimensions\n",
    "c = torch.arange(60).reshape(3, 4, 5)\n",
    "c, c[0, ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elementwise operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Apply relu to tensor `a` and print results\n",
    "a = torch.arange(-5, 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Broadcasting\n",
    "Broadcasting rules:\n",
    "- Right-most dimensions matches\n",
    "- A dimension has size 1 (including scalars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We would expect without broadcasting to apply all operations elementwise with operands of the same size\n",
    "a = torch.Tensor([1, 2, 3])\n",
    "b = torch.Tensor([10, 10, 10])\n",
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Broadcasting to add a scalar to a tensor\n",
    "a + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Adding a vector to each row of a matrix\n",
    "a = torch.arange(12).reshape(3, 4)  # Matrix of size (3, 4)\n",
    "b = torch.Tensor([1, 10, 100, 200])  # Column vector of size (4,)\n",
    "# Sizes: (3, 4) + (4,)\n",
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Creating a boolean mask from a tensor\n",
    "a = torch.arange(12).reshape(3, 4)\n",
    "a < 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Adding a tensor that has a singleton dimension\n",
    "a = torch.randn((2, 4, 3, 10))\n",
    "b = torch.randn((4, 1, 10))\n",
    "# (2, 4, 3, 10)\n",
    "#    (4, 1, 10)\n",
    "# =============\n",
    "# (2, 4, 3, 10)\n",
    "\n",
    "# Note that b with shape (4, 10) will not broadcast\n",
    "# b = torch.randn((4, 10))\n",
    "\n",
    "c = a + b\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Transform a random normal tensor of shape (3, 10)\n",
    "# The columns should have means of [-3, 5, 100] and standard deviations of [0.1, 1, 10]\n",
    "a = torch.randn((10, 3))  # Shape     (10, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix multiplication\n",
    "\n",
    "Matmul rules:\n",
    "- A has shape `(..., l, m)`\n",
    "- B has shape `     (m, n)`\n",
    "- Last dimension of A must have same as second-last dimension of B\n",
    "- Transform last dimension of A from `m` to `n`\n",
    "- Can use `torch.mm()` or `@` operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Multiply two matrices\n",
    "A = torch.randn((3, 5))\n",
    "B = torch.randn((5, 10))\n",
    "# (3, 5)  @ (5, 10) -> (3, 10)\n",
    "C = A @ B\n",
    "C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Matmul can be broadcasted\n",
    "A = torch.randn((4, 32, 32, 3))\n",
    "B = torch.randn((3, 10))\n",
    "# (4, 32, 32, 3) @ (3, 10) -> (4, 32, 32, 10)\n",
    "C = A @ B\n",
    "C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Transform this batch of vector sequences from feature size 7 to feature size 32 through matmul\n",
    "A = torch.randn(4, 100, 7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduction operations\n",
    "Reduction operation rules:\n",
    "- By default reduces across whole tensor\n",
    "- Specify the `dim` keyword to specify reduction dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(12).reshape(3, 4)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Sum all elements of a\n",
    "a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Sum along rows (dim=0)\n",
    "a.sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Sum along columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compute the mean and standard deviation of this tensor along rows\n",
    "a = torch.randn((10, 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshape operations\n",
    "- `x.reshape(shape)`: Reshapes to `shape`, product of dims must be same before and after\n",
    "- `x.squeeze()`: Remove singleton dims\n",
    "- `x.unsqueeze(d)`: Add a singleton dim at dimension `d`\n",
    "- `x.flatten()`: Unravel into a vector of shape `(x.size,)`\n",
    "- `x.permute(order)`: Permute order of dims according to a tuple of dims\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(60).reshape(3, 1, 4, 5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Reshape to (2, 30)\n",
    "a.reshape(2, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Squeeze out extra dimension\n",
    "a.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Flatten into a vector\n",
    "a.flatten(), a.flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Flatten just the last two dims\n",
    "a.flatten(-2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Permute order of dims to (1, 5, 4, 3)\n",
    "# (3, 1, 4, 5)\n",
    "# (0, 1, 2, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity: Process the logistic regression data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLAB\n",
    "# !git clone https://github.com/trevor-yu-087/syde-599-f23-tutorial\n",
    "# DATA_PATH = \"/content/syde-599-f23-tutorial/data/logistic-regression-data.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"data/logistic-regression-data.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "x = data[\"training_x\"]\n",
    "x.shape, type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Convert the data to a tensor in float32 dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compute the mean and std over the batch dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Standardize the data by subtracting the mean and dividing by std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Verify the new mean/std are standard normal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity: Linear layer\n",
    "The `torch.nn.Linear(m, n)` layer applies the equation `y = x @ w + b` such that `w` is a weight matrix of shape (m, n), b is a bias vector of length (n) and takes `x` from shape (b, m) to `y` with shape (b, n)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Apply a Linear layer transformation to this feature matrix.\n",
    "# The resultant tensor, y, should have shape (100, 16)\n",
    "x = torch.randn(100, 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Convert x to shape that is compatible with this matmul to result in a tensor of shape (3, 5, 7)\n",
    "x = torch.randn(3, 4, 5)\n",
    "w = torch.randn(4, 7)\n",
    "b = torch.randn(7)\n",
    "\n",
    "\n",
    "y = x @ w + b\n",
    "y.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
