{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import gymnasium as gym\n",
    "import ale_py\n",
    "import highway_env\n",
    "from highway_env.envs.intersection_env import IntersectionEnv\n",
    "\n",
    "from option_critic import OptionCriticFeatures\n",
    "from attention_option_critic import AOCFeatures\n",
    "from fourrooms_env import Fourrooms\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_PARAMS = {\"cartpole\": {\"oc\": {'num_options': 10, 'temperature': 1.3717722079389996, 'epsilon_start': 0.900845670626169, 'epsilon_min': 0.08330863818091966, 'epsilon_decay': 143651, 'gamma': 0.9719127696965757, 'tau': 0.9571360946012313, 'termination_reg': 0.008253268020968376, 'entropy_reg': 0.026949261891458975, 'hidden_size': 40, 'state_size': 56, 'hidden_size_2': None, 'hidden_size_Q': None, 'hidden_size_termination': None, 'hidden_size_policy': None, 'learning_rate': 0.002872637446118515, 'batch_size': 224, 'critic_freq': 10, 'target_update_freq': 20, 'buffer_size': 4000},\n",
    "                            \"aoc\": {'num_options': 9, 'temperature': 0.7014647237611604, 'epsilon_start': 0.9266293878140235, 'epsilon_min': 0.1477058909278815,  'epsilon_decay': 696722, 'gamma': 0.8995605059962165, 'tau': 0.9876976682663541, 'termination_reg': 0.02136841630458894, 'entropy_reg': 0.0072884705990544025, 'diversity_reg': 0.03153052105606061, 'sparsity_reg': 0.006558493362079418, 'smoothness_reg': 0.007593783252036938, 'hidden_size': 112, 'state_size': 32, 'learning_rate': 0.001247281645969728,  'batch_size': 224, 'critic_freq': 80, 'target_update_freq': 15, 'buffer_size': 3000}},\n",
    "               \"fourrooms\": {\"oc\": {'num_options': 7, 'temperature': 1.2736018552613575, 'epsilon_start': 0.898407044702919, 'epsilon_min': 0.11106037082599012, 'epsilon_decay': 2017100, 'gamma': 0.6355538088726308, 'tau': 0.994875240587202, 'termination_reg': 6.208141298922531, 'entropy_reg': 36.876883358671854, 'hidden_size': 176, 'state_size': 88, 'hidden_size_2': 176, 'hidden_size_Q': 64, 'hidden_size_termination': 32, 'hidden_size_policy': 168, 'use_hidden_size': True, 'use_hidden_size_2': True, 'use_hidden_size_Q': True, 'use_hidden_size_termination': True, 'use_hidden_size_policy': True, 'learning_rate': 1.2677056587562904e-05, 'batch_size': 288, 'critic_freq': 87, 'target_update_freq': 20, 'buffer_size': 9000},\n",
    "                             \"aoc\": {'num_options': 4, 'temperature': 1, 'epsilon_start': 0.93, 'epsilon_min': 0.148,  'epsilon_decay': 696722, 'gamma': 0.9, 'tau': 0.988, 'termination_reg': 0.0214, 'entropy_reg': 0.00729, 'diversity_reg': 0.0315, 'sparsity_reg': 0.00656, 'smoothness_reg': 0.00759, 'hidden_size': 112, 'state_size': 32, 'learning_rate': 0.00125,  'batch_size': 224, 'critic_freq': 80, 'target_update_freq': 15, 'buffer_size': 3000}},    # TODO\n",
    "               \"highway\": {\"oc\": {'num_options': 6, 'temperature': 1.2373617037978715, 'epsilon_start': 0.8677873957612043, 'epsilon_min': 0.0467816977436859, 'epsilon_decay': 416087, 'gamma': 0.8487674660379827, 'tau': 0.9539181690135505, 'termination_reg': 0.046733452793875675, 'entropy_reg': 0.014710831617644375, 'hidden_size': 112, 'state_size': 96, 'learning_rate': 0.00010708727747293872, 'batch_size': 128, 'critic_freq': 80, 'target_update_freq': 15, 'buffer_size': 1000},  # TODO\n",
    "                           \"aoc\": {}},    # TODO\n",
    "               \"intersection\": {\"oc\": {'num_options': 6, 'temperature': 1.2373617037978715, 'epsilon_start': 0.8677873957612043, 'epsilon_min': 0.0467816977436859, 'epsilon_decay': 416087, 'gamma': 0.8487674660379827, 'tau': 0.9539181690135505, 'termination_reg': 0.046733452793875675, 'entropy_reg': 0.014710831617644375, 'hidden_size': 112, 'state_size': 96, 'learning_rate': 0.00010708727747293872, 'batch_size': 128, 'critic_freq': 80, 'target_update_freq': 15, 'buffer_size': 1000},  # TODO\n",
    "                                \"aoc\": {}}}  # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_IDX = 1\n",
    "ENV_NAME =    [\"CartPole-v1\", \"Fourrooms\", \"highway-fast-v0\", \"intersection-v1\", \"racetrack-v0\", \"ALE/Pong-v5\"][ENV_IDX]\n",
    "ENV_TYPE =    [\"cartpole\",    \"fourrooms\", \"highway\",         \"intersection\",    \"racetrack\",    \"pong\"][ENV_IDX]\n",
    "RENDER_MODE = [\"human\",       \"rgb_array\", \"rgb_array\",       \"rgb_array\",       \"rgb_array\",    \"human\"][ENV_IDX]\n",
    "TOTAL_TIMESTEPS = int(1e5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Feature input, Discrete action space\n",
    "    - \"CartPole-v1\"      # (4,) --> 2\n",
    "    - \"LunarLander-v3\"     # (8,) --> 4\n",
    "    - \"highway-fast-v0\"  # (5, 5) --> 5\n",
    "    - \"intersection-v0\"  # (15, 7) --> 3\n",
    "\n",
    "- Feature input, Continuous action space\n",
    "    - \"intersection-v1\"  # (5, 8) --> -1, 1, (2,)\n",
    "    - \"racetrack-v0\"     # (2, 12, 12)\n",
    "\n",
    "- Image input, Discrete action space\n",
    "    - \"ALE/Pong-v5\"    # (210, 160, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(env, env_type, model_type, train=False, record=False, save=False, total_timesteps=TOTAL_TIMESTEPS):\n",
    "    model_params = BEST_PARAMS[env_type][model_type]\n",
    "    \n",
    "    if model_type == \"aoc\":\n",
    "        model = AOCFeatures(\n",
    "            env=env,\n",
    "            num_options=model_params[\"num_options\"],\n",
    "            device=\"cpu\",\n",
    "            \n",
    "            temperature=model_params[\"temperature\"],\n",
    "            epsilon_start=model_params[\"epsilon_start\"],\n",
    "            epsilon_min=model_params[\"epsilon_min\"],\n",
    "            epsilon_decay=model_params[\"epsilon_decay\"],\n",
    "            gamma=model_params[\"gamma\"],\n",
    "            tau=model_params[\"tau\"],\n",
    "            \n",
    "            termination_reg=model_params[\"termination_reg\"],\n",
    "            entropy_reg=model_params[\"entropy_reg\"],\n",
    "            diversity_reg=model_params[\"diversity_reg\"],\n",
    "            sparsity_reg=model_params[\"sparsity_reg\"],\n",
    "            smoothness_reg=model_params[\"smoothness_reg\"],\n",
    "            \n",
    "            hidden_size=model_params[\"hidden_size\"],\n",
    "            state_size=model_params[\"state_size\"],\n",
    "            hidden_size_2=model_params[\"hidden_size_2\"],\n",
    "            hidden_size_Q=model_params[\"hidden_size_Q\"],\n",
    "            hidden_size_termination=model_params[\"hidden_size_termination\"],\n",
    "            hidden_size_policy=model_params[\"hidden_size_policy\"],\n",
    "            hidden_size_attention=model_params[\"hidden_size_attention\"],\n",
    "            use_hidden_size=model_params[\"use_hidden_size\"],\n",
    "            use_hidden_size_2=model_params[\"use_hidden_size_2\"],\n",
    "            use_hidden_size_Q=model_params[\"use_hidden_size_Q\"],\n",
    "            use_hidden_size_termination=model_params[\"use_hidden_size_termination\"],\n",
    "            use_hidden_size_policy=model_params[\"use_hidden_size_policy\"],\n",
    "            use_hidden_size_attention=model_params[\"use_hidden_size_attention\"],\n",
    "            \n",
    "            learning_rate=model_params[\"learning_rate\"],\n",
    "            batch_size=model_params[\"batch_size\"],\n",
    "            critic_freq=model_params[\"critic_freq\"],\n",
    "            target_update_freq=model_params[\"target_update_freq\"],\n",
    "            buffer_size=model_params[\"buffer_size\"],\n",
    "            tensorboard_log=f\"results/{env_type}_{model_type}/\" if record else None,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "    elif model_type == \"oc\":\n",
    "        model = OptionCriticFeatures(\n",
    "            env=env,\n",
    "            num_options=model_params[\"num_options\"],\n",
    "            device=\"cpu\",\n",
    "            \n",
    "            temperature=model_params[\"temperature\"],\n",
    "            epsilon_start=model_params[\"epsilon_start\"],\n",
    "            epsilon_min=model_params[\"epsilon_min\"],\n",
    "            epsilon_decay=model_params[\"epsilon_decay\"],\n",
    "            gamma=model_params[\"gamma\"],\n",
    "            tau=model_params[\"tau\"],\n",
    "            \n",
    "            termination_reg=model_params[\"termination_reg\"],\n",
    "            entropy_reg=model_params[\"entropy_reg\"],\n",
    "            \n",
    "            hidden_size=model_params[\"hidden_size\"],\n",
    "            state_size=model_params[\"state_size\"],\n",
    "            hidden_size_2=model_params[\"hidden_size_2\"],\n",
    "            hidden_size_Q=model_params[\"hidden_size_Q\"],\n",
    "            hidden_size_termination=model_params[\"hidden_size_termination\"],\n",
    "            hidden_size_policy=model_params[\"hidden_size_policy\"],\n",
    "            use_hidden_size=model_params[\"use_hidden_size\"],\n",
    "            use_hidden_size_2=model_params[\"use_hidden_size_2\"],\n",
    "            use_hidden_size_Q=model_params[\"use_hidden_size_Q\"],\n",
    "            use_hidden_size_termination=model_params[\"use_hidden_size_termination\"],\n",
    "            use_hidden_size_policy=model_params[\"use_hidden_size_policy\"],\n",
    "            \n",
    "            learning_rate=model_params[\"learning_rate\"],\n",
    "            batch_size=model_params[\"batch_size\"],\n",
    "            critic_freq=model_params[\"critic_freq\"],\n",
    "            target_update_freq=model_params[\"target_update_freq\"],\n",
    "            buffer_size=model_params[\"buffer_size\"],\n",
    "            tensorboard_log=f\"results/{env_type}_{model_type}/\" if record else None,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "    if train:\n",
    "        model.learn(total_timesteps=total_timesteps)\n",
    "        if save:\n",
    "            model.save(f\"results/{env_type}_{model_type}/model\")\n",
    "    else:\n",
    "        model.load(f\"results/{env_type}_{model_type}/best_model\")\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_env():\n",
    "    if ENV_TYPE == \"fourrooms\":\n",
    "        env = Fourrooms()\n",
    "        render_env = Fourrooms(render_mode=RENDER_MODE)\n",
    "    elif ENV_TYPE == \"intersection\":\n",
    "        intersection_config = IntersectionEnv.default_config()\n",
    "        discrete_action = {'type': 'DiscreteAction', \n",
    "                        'longitudinal': False, \n",
    "                        'lateral': True, \n",
    "                        'target_speeds': [0, 5, 10]}\n",
    "        intersection_config[\"observation\"][\"action\"] = discrete_action\n",
    "        intersection_config[\"action\"] = discrete_action\n",
    "        env = IntersectionEnv(config=intersection_config)\n",
    "        render_env = IntersectionEnv(config=intersection_config, render_mode=RENDER_MODE)\n",
    "    else:\n",
    "        env = gym.make(ENV_NAME)\n",
    "        render_env = gym.make(ENV_NAME, render_mode=RENDER_MODE)\n",
    "        \n",
    "    return env, render_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This crashes if run in .ipynb instead of .py\n",
    "def simulate_env(model, env, num_episodes=10):\n",
    "    for episode in range(num_episodes):\n",
    "        done = truncated = False\n",
    "        obs, info = env.reset()\n",
    "        option = None\n",
    "        option_termination = True\n",
    "        while not (done or truncated):\n",
    "            option, action, logp, entropy = model.predict(obs, option, option_termination, testing=True)\n",
    "            option_termination = model.get_option_termination(obs, option)\n",
    "            obs, reward, done, truncated, info = env.step(action)\n",
    "            env.render()\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_stats(model, env, num_episodes=100):\n",
    "    num_actions = env.action_space.n\n",
    "    num_options = model.num_options\n",
    "    option_actions = np.zeros((num_actions, num_options))\n",
    "    \n",
    "    # Collect data for visualizations\n",
    "    if ENV_TYPE == \"fourrooms\":\n",
    "        state_visits = np.zeros_like(env.occupancy, dtype=np.float32)  # Fourrooms only\n",
    "        option_terminations = np.zeros((num_options, *env.occupancy.shape), dtype=np.float32)   # Fourrooms only\n",
    "        for episode in tqdm(range(num_episodes)):\n",
    "            done = truncated = False\n",
    "            obs, info = env.reset()\n",
    "            option = None\n",
    "            option_termination = True\n",
    "            while not (done or truncated):\n",
    "                option, action, logp, entropy = model.predict(obs, option, option_termination, testing=True)\n",
    "                option_actions[action, option] += 1\n",
    "                state_visits[env.curr_cell[0], env.curr_cell[1]] += 1   # Fourrooms only\n",
    "                option_termination = model.get_option_termination(obs, option)\n",
    "                if option_termination:  # Fourrooms only: Record option termination locations\n",
    "                    option_terminations[option, env.curr_cell[0], env.curr_cell[1]] += 1\n",
    "                obs, reward, done, truncated, info = env.step(action)\n",
    "    else:\n",
    "        for episode in tqdm(range(num_episodes)):\n",
    "            done = truncated = False\n",
    "            obs, info = env.reset()\n",
    "            option = None\n",
    "            option_termination = True\n",
    "            while not (done or truncated):\n",
    "                option, action, logp, entropy = model.predict(obs, option, option_termination, testing=True)\n",
    "                option_actions[action, option] += 1\n",
    "                option_termination = model.get_option_termination(obs, option)\n",
    "                obs, reward, done, truncated, info = env.step(action)\n",
    "        env.close()\n",
    "    \n",
    "    # 1. Primitive actions per option (Normalize across options)\n",
    "    option_sums = option_actions.sum(axis=0)\n",
    "    norm_option_actions = np.zeros_like(option_actions, dtype=float)\n",
    "    for col in range(option_actions.shape[1]):\n",
    "        if option_sums[col] > 0:\n",
    "            norm_option_actions[:, col] = option_actions[:, col] / option_sums[col]\n",
    "\n",
    "    plt.figure(figsize=(num_options+1, num_actions))\n",
    "    plt.imshow(norm_option_actions, cmap=\"viridis\", aspect=\"auto\")\n",
    "    plt.colorbar(label=\"Frequency\")\n",
    "    plt.xlabel(\"Options\")\n",
    "    plt.ylabel(\"Actions\")\n",
    "    plt.title(\"Distribution of Primitive Actions Per Option\")\n",
    "    plt.xticks(ticks=np.arange(num_options))\n",
    "    plt.yticks(ticks=np.arange(num_actions))\n",
    "    plt.show()\n",
    "    \n",
    "    # 2. Options per primitive action (Normalize across actions)\n",
    "    action_sums = option_actions.sum(axis=1)\n",
    "    norm_action_options = np.zeros_like(option_actions, dtype=float)\n",
    "    for row in range(option_actions.shape[0]):\n",
    "        if action_sums[row] > 0:\n",
    "            norm_action_options[row, :] = option_actions[row, :] / action_sums[row]\n",
    "\n",
    "    plt.figure(figsize=(num_options+1, num_actions))\n",
    "    plt.imshow(norm_action_options, cmap=\"viridis\", aspect=\"auto\")\n",
    "    plt.colorbar(label=\"Frequency\")\n",
    "    plt.xlabel(\"Options\")\n",
    "    plt.ylabel(\"Actions\")\n",
    "    plt.title(\"Distribution of Options Per Action (Normalized by Actions)\")\n",
    "    plt.xticks(ticks=np.arange(num_options))\n",
    "    plt.yticks(ticks=np.arange(num_actions))\n",
    "    plt.show()\n",
    "    \n",
    "    # 3. Histogram for total option usage\n",
    "    option_totals = option_actions.sum(axis=0)\n",
    "    total_usage = option_totals.sum()\n",
    "    option_percent = (option_totals / total_usage) * 100\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    bars = plt.bar(range(num_options), option_percent, color=\"steelblue\")\n",
    "    plt.xlabel(\"Options\")\n",
    "    plt.ylabel(\"Usage Percentage (%)\")\n",
    "    plt.title(\"Percentage Usage of Each Option\")\n",
    "    plt.xticks(ticks=np.arange(num_options))\n",
    "    plt.ylim(0, option_percent.max() + 5)\n",
    "    \n",
    "    # Display the percentage number above each bar\n",
    "    for i, bar in enumerate(bars):\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 1, \n",
    "                 f\"{option_percent[i]:.2f}%\", ha='center', va='bottom', fontsize=10)\n",
    "    plt.show()\n",
    "    \n",
    "    # 4. Fourrooms only: State visitation heatmap\n",
    "    state_visits_normalized = state_visits / state_visits.max() # Normalize visits between 0 and 1\n",
    "    grid = np.array(env.occupancy, dtype=np.float32)            # Copy the occupancy grid\n",
    "    heatmap = np.zeros_like(grid, dtype=np.float32)             # Initialize cells to 0\n",
    "    heatmap[grid == 0] = state_visits_normalized[grid == 0]     # Copy visitation frequencies if cell is not a wall\n",
    "\n",
    "    cmap = plt.cm.viridis\n",
    "    heatmap_rgb = cmap(heatmap)[:, :, :3]   # Make heatmap using viridis\n",
    "    heatmap_rgb[grid == 1] = [0, 0, 0]      # Set walls to black\n",
    "    goal_cell = env.to_cell[env.goal]\n",
    "    heatmap_rgb[goal_cell[0], goal_cell[1]] = [1, 0, 0]  # Set the goal cell to red\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(heatmap_rgb, aspect=\"equal\")\n",
    "    plt.xlabel(\"X Coordinate\")\n",
    "    plt.ylabel(\"Y Coordinate\")\n",
    "    plt.title(\"State Visitation Heatmap\")\n",
    "    plt.show()\n",
    "    \n",
    "    # # 5. Fourrooms only: Option termination heatmap\n",
    "    # option_terminations_normalized = option_terminations / option_terminations.max(axis=(1, 2), keepdims=True)  # Normalize terminations between 0 and 1\n",
    "    \n",
    "    # for opt in range(num_options):\n",
    "    #     grid = np.array(env.occupancy, dtype=np.float32)  # Copy the occupancy grid\n",
    "    #     heatmap = np.zeros_like(grid, dtype=np.float32)   # Initialize cells to 0\n",
    "    #     heatmap[grid == 0] = option_terminations_normalized[opt, grid == 0]  # Copy termination frequencies\n",
    "\n",
    "    #     cmap = plt.cm.viridis\n",
    "    #     heatmap_rgb = cmap(heatmap)[:, :, :3]  # Make heatmap using viridis\n",
    "    #     heatmap_rgb[grid == 1] = [0, 0, 0]     # Set walls to black\n",
    "    #     goal_cell = env.to_cell[env.goal]\n",
    "    #     heatmap_rgb[goal_cell[0], goal_cell[1]] = [1, 0, 0]  # Set the goal cell to red\n",
    "\n",
    "    #     plt.figure(figsize=(10, 10))\n",
    "    #     plt.imshow(heatmap_rgb, aspect=\"equal\")\n",
    "    #     plt.xlabel(\"X Coordinate\")\n",
    "    #     plt.ylabel(\"Y Coordinate\")\n",
    "    #     plt.title(f\"Option Termination Heatmap: Option {opt}\")\n",
    "    #     plt.colorbar(label=\"Normalized Termination Frequency\")\n",
    "    #     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env, render_env = get_env()\n",
    "oc = get_model(env=env, env_type=ENV_TYPE, model_type=\"oc\", train=False, record=False, save=False)\n",
    "\n",
    "# simulate_env(oc, render_env, num_episodes=10)\n",
    "visualize_stats(oc, env=env, num_episodes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize AOC attentions per option for each input feature\n",
    "def get_attention_per_feature(model, env, num_episodes=10):\n",
    "    num_features = model.in_features\n",
    "    num_options = model.num_options\n",
    "    option_attentions = np.zeros((num_options, num_features))\n",
    "    \n",
    "    # Collect data for visualizations\n",
    "    for episode in tqdm(range(num_episodes)):\n",
    "        done = truncated = False\n",
    "        obs, info = env.reset()\n",
    "        option = None\n",
    "        option_termination = True\n",
    "        while not (done or truncated):\n",
    "            option, action, logp, entropy = model.predict(obs, option, option_termination, testing=True)\n",
    "            \n",
    "            _, attention_mask = model.apply_attention(obs, option)\n",
    "            attention_mask = attention_mask.detach().cpu().numpy().squeeze()\n",
    "            option_attentions[option, :] += attention_mask\n",
    "            \n",
    "            option_termination = model.get_option_termination(obs, option)\n",
    "            obs, reward, done, truncated, info = env.step(action)\n",
    "    env.close()\n",
    "    \n",
    "    # Normalize across options (feature contributions to each option sum to 1)\n",
    "    option_sums = option_attentions.sum(axis=1, keepdims=True)\n",
    "    norm_feature_per_option = np.zeros_like(option_attentions, dtype=float)\n",
    "    for row in range(option_attentions.shape[0]):\n",
    "        if option_sums[row] > 0:\n",
    "            norm_feature_per_option[row, :] = option_attentions[row, :] / option_sums[row]\n",
    "\n",
    "    plt.figure(figsize=(num_features + 1, num_options))\n",
    "    plt.imshow(norm_feature_per_option, cmap=\"viridis\", aspect=\"auto\")\n",
    "    plt.colorbar(label=\"Attention Weight\")\n",
    "    plt.xlabel(\"Features\")\n",
    "    plt.ylabel(\"Options\")\n",
    "    plt.title(\"Normalized Attention Distribution (Features per Option)\")\n",
    "    plt.xticks(ticks=np.arange(num_features))\n",
    "    plt.yticks(ticks=np.arange(num_options))\n",
    "    plt.show()\n",
    "\n",
    "    # Normalize across features (option contributions to each feature sum to 1)\n",
    "    feature_sums = option_attentions.sum(axis=0, keepdims=True)\n",
    "    norm_option_per_feature = np.zeros_like(option_attentions, dtype=float)\n",
    "    for col in range(option_attentions.shape[1]):\n",
    "        if feature_sums[0, col] > 0:\n",
    "            norm_option_per_feature[:, col] = option_attentions[:, col] / feature_sums[0, col]\n",
    "\n",
    "    plt.figure(figsize=(num_features + 1, num_options))\n",
    "    plt.imshow(norm_option_per_feature, cmap=\"plasma\", aspect=\"auto\")\n",
    "    plt.colorbar(label=\"Attention Weight\")\n",
    "    plt.xlabel(\"Features\")\n",
    "    plt.ylabel(\"Options\")\n",
    "    plt.title(\"Normalized Attention Distribution (Options per Feature)\")\n",
    "    plt.xticks(ticks=np.arange(num_features))\n",
    "    plt.yticks(ticks=np.arange(num_options))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env, render_env = get_env()\n",
    "# aoc = get_model(env=env, env_type=ENV_TYPE, model_type=\"aoc\", train=True, record=True)\n",
    "\n",
    "# simulate_env(aoc, env=render_env, num_episodes=1)\n",
    "# visualize_stats(aoc, env=env, num_episodes=100)\n",
    "# get_attention_per_feature(aoc, env=env, num_episodes=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "highway",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
